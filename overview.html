<!DOCTYPE HTML>
<!--
	Arcana by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>MISP Challenge-Overview</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header">

					<!-- Logo -->
						<h1 style="font-size: 180%; margin: -20px 0 -60px"> Multimodal Information based Speech Processing Challenge 2021 </h1>

					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="index.html">Home</a></li>
								<li class="current"><a href="overview.html">Overview</a><li>
								<li>
									<a href="#">Track1</a>
									<ul>
										<li><a href="#">Data</a></li>
										<li><a href="#">Software</a></li>
										<li><a href="#">Instructions</a></li>
						                                <li><a href="#">Submission</a></li>
									</ul>
								</li>
								<li>
									<a href="#">Track2</a>
									<ul>
										<li><a href="#">Data</a></li>
										<li><a href="#">Software</a></li>
										<li><a href="#">Instructions</a></li>
						                                <li><a href="#">Submission</a></li>
									</ul>
								</li>
								<li><a href="left-sidebar.html">Download</a></li>
								<li><a href="right-sidebar.html">Results</a></li>
								<li><a href="two-sidebar.html">Contact</a></li>
								<li><a href="no-sidebar.html">Forum</a></li>
							</ul>
						</nav>

				</div>

			<!-- Main -->
				<section class="wrapper style1">
					<div class="container">
						<div id="content">

							<!-- Content -->

								<article>
									<header>
										<h1>Task Overview</h1>
                    <h3>Background</h3>
                  </header>
										<p>Automatic speech recognition (ASR) system was proposed as an important interface for human-computer interaction. Modern ASR systems still suffer from performance degradations in real world environments due to adverse acoustic conditions, such as channel distortion, ambient noise and reverberation, etc. In the last decade, ASR performance in difficult reverberant and noisy conditions has improved tremendously. This can be attributed to technology advances in speech enhancement and robust speech recognition, but also to the availability of speech corpora recorded in various real environments.Recently, more and more researches proposed visual cues such as facial/lip movements can help speech perception, through supplementing the acoustic information related to the corresponding speaker, especially in noisy environments. Various audio-visual speech corpora were released to support research, but there is still a lack of a large-scale public audio-visual speech corpus recorded in real world scenes, especially for Chinese language.</p>
									
									<h3>Scenario</h3>
									
										<p>We consider the following scenario: several people are chatting while watching TV in the living room, and they can interact with a smart speaker/TV. With the multimodal data collected by microphones and cameras, we can conduct the research to solve the following five speech processing tasks:</p>
									        <u1>
						                                  <li>Voice Wake-up: saying a keyword to wake up the smart speaker/TV.</li>
										  <li>Voice Activity Detection (VAD): filtering the non-speech segments.</li>
										  <li>Speaker Diarization: partitioning the speech segments into homogeneous groups corresponding to the speaker identity.</li>
										  <li>Speech Separation & Enhancement: segregating the overlapping speech segments and denoising.</li>
										  <li>Speech Recognition.</li>
									        </u1>
									        <p>All five tasks suffer from performance degradations yielded by adverse acoustic conditions in the Home TV scene described above and the final recognition result is seriously distorted. We proposed the visual modality could be a powerful supplement input for anyone system.</p>

									        <p>We aim to support the research about audio-visual speech processing in the Home TV scene by providing the first large-scale audio-visual corpus of multi-speaker conversational speech recorded via multi-microphone hardware in real living rooms. An example of the recording scene is shown in Fig.1. Six participants are chatting while multiple devices are used to record audio and video in parallel. </p>
			                                                          <center>
                                                                                    <figure style="padding:0px;border:0px; margin:25px">
                                                                                    <img src="images/exp1.jpg" alt="An example of recording in home TV scenario" style="width:600px;padding:0px;border:0" />
                                                                                    <figcaption>Fig1.An example of recording in home TV scenario</figcaption>
                                                                                    </figure>
									          </center>
									
									<h3>Device</h3>
									        <center>
                                                                                    <figure style="padding:0px;border:0px; margin:10px">
                                                                                    <img src="images/Fig2.jpg" alt="Figure2:A real shot of recording in home TV scenario" style="width:620px;padding:0px;border:0" />
                                                                                    <figcaption>Figure2:A real shot of recording in home TV scenario</figcaption>
                                                                                    </figure>
									        </center>
									        <p>A real shot of the recording scene is shown in Fig.2. According to the distance between the device and the speaker, multiple recording devices were divided into 3 categories:</p>
									        <p>A.Far devices: a linear microphone array (6 mic, 16 kHz, 16-bit) and a wide-angle camera (1080p, 25 fps, 2pi/3), which are placed 3-5m away from the speaker. All participants appear in the camera, which brings speakers position information while reducing the resolution of the lip region of interest (ROI);
										<p>B.Middle devices: a linear microphone array (2 mic, 44.1 kHz, 16-bit) and n high-definition cameras (720p, 25fps, pi/2), which are placed 0.8-1.5m away from the speaker, where n is the number of participants within this conversation. There is only the corresponding speaker in each camera, the lip ROI is recorded clearly;</p>
									        <p>C.Near devices: n high-fidelity microphones (44.1 kHz, 16-bit), which were stuck in the middle of the corresponding speaker's chin, respectively. The collected audio signal is rarely interfered by the off-target source and the SNR is estimated to be greater than 15 db. This provides a guarantee for high-quality manual transcription.</p>
									        <center>
                                                                                    <figure style="padding:0px;border:0px; margin:10px">
                                                                                    <img src="images/Fig3.jpg" alt="Figure3:Real shots of various devices" style="width:700px;padding:0px;border:0" />
                                                                                    <figcaption>Figure3:Real shots of various devices</figcaption>
                                                                                    </figure>
									        </center>
									        <p>Fig.3 shows real shots of various devices. Various devices have resulted in inconsistent clocks. We address this from two aspects: synchronization devices and manual post-processing.</p>
									        <p>D.Synchronization devices: the sound card (ZOOM F8n) is used to synchronize the clock of the middle linear microphone array and the clocks of near high-fidelity microphones while Vicando software, running on the industrial PC (MIC-770), is used to synchronize the clocks of all cameras.</p>
									        <p>Even if synchronization devices were used, there are still 3 different clocks, i.e. the clock of the sound card, the clock of the far linear microphone array and the clock of the industrial PC. They are synchronized by finding the mark point manually. A specific behavior, i.e. knocking the cup, would be done while the recording is started. The visual frame where the cup wall and the cup cover are in contact and the waveform point which is corresponding to the impact sound are aligned manually.</p>
									
									<h3>Tracks</h3>
									       <p>Based on our annotations for current corpus, actually we can set all 5 tasks, namely:</p>
									       <u1>
						                                  <li>Audio-visual wake-up</li>
										  <li>Audio-visual VAD</li>
										  <li>Audio-visual speech enhancement/separation</li>
										  <li>Audio-visual speaker diariazation</li>
										  <li>Audio-visual speech recognition</li>
									       </u1>
									
								</article>

						</div>
					</div>
				</section>

			<!-- Footer -->
				<div id="footer">
					<div class="container">
						<div class="row">
							<section class="col-3 col-6-narrower col-12-mobilep">
								<h3>Links to Stuff</h3>
								<ul class="links">
									<li><a href="#">Mattis et quis rutrum</a></li>
									<li><a href="#">Suspendisse amet varius</a></li>
									<li><a href="#">Sed et dapibus quis</a></li>
									<li><a href="#">Rutrum accumsan dolor</a></li>
									<li><a href="#">Mattis rutrum accumsan</a></li>
									<li><a href="#">Suspendisse varius nibh</a></li>
									<li><a href="#">Sed et dapibus mattis</a></li>
								</ul>
							</section>
							<section class="col-3 col-6-narrower col-12-mobilep">
								<h3>More Links to Stuff</h3>
								<ul class="links">
									<li><a href="#">Duis neque nisi dapibus</a></li>
									<li><a href="#">Sed et dapibus quis</a></li>
									<li><a href="#">Rutrum accumsan sed</a></li>
									<li><a href="#">Mattis et sed accumsan</a></li>
									<li><a href="#">Duis neque nisi sed</a></li>
									<li><a href="#">Sed et dapibus quis</a></li>
									<li><a href="#">Rutrum amet varius</a></li>
								</ul>
							</section>
							<section class="col-6 col-12-narrower">
								<h3>Get In Touch</h3>
								<form>
									<div class="row gtr-50">
										<div class="col-6 col-12-mobilep">
											<input type="text" name="name" id="name" placeholder="Name" />
										</div>
										<div class="col-6 col-12-mobilep">
											<input type="email" name="email" id="email" placeholder="Email" />
										</div>
										<div class="col-12">
											<textarea name="message" id="message" placeholder="Message" rows="5"></textarea>
										</div>
										<div class="col-12">
											<ul class="actions">
												<li><input type="submit" class="button alt" value="Send Message" /></li>
											</ul>
										</div>
									</div>
								</form>
							</section>
						</div>
					</div>

					<!-- Icons -->
						<ul class="icons">
							<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
							<li><a href="#" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
							<li><a href="#" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
							<li><a href="#" class="icon brands fa-google-plus-g"><span class="label">Google+</span></a></li>
						</ul>

					<!-- Copyright -->
						<div class="copyright">
							<ul class="menu">
								<li>&copy; Untitled. All rights reserved</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>

				</div>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
